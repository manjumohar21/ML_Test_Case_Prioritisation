# ML-Driven Test Case Prioritization
![Python](https://img.shields.io/badge/Python-3.10-blue)
![License](https://img.shields.io/badge/License-MIT-green)

This project demonstrates how to use **Machine Learning** to prioritize regression test cases based on historical execution data, helping reduce regression time and improve defect detection.
---

##  Overview
- Predicts which test cases are most likely to fail using a **Random Forest Classifier**.
- Prioritizes high-risk tests for execution.
- Includes **visualizations** showing feature relationships and test prioritization.

---

##  Features
- **FailureRate**: Historical failure frequency of the test case.  
- **LinesChanged**: Number of lines changed in related modules.  
- **ExecTime**: Execution time of the test case.  
- **RecentFails**: Number of recent failures in related modules.  

---

## Target
- **Label**: 1 = likely fail (high priority), 0 = likely pass (low priority).

---

##  Visualizations
**Example charts generated by the script:**

- **Bar chart**: Shows predicted failure probabilities of test cases.  

<img width="851" height="578" alt="image" src="https://github.com/user-attachments/assets/39362e24-0c77-4a0c-9bab-2c3f5b1a3154" />


- **Pairplot**: Shows feature relationships and how they influence test case priority.  

<img width="695" height="473" alt="image" src="https://github.com/user-attachments/assets/48de0818-0af8-4119-b7a4-562b1442ef2a" />

---

## Dummy Data
Example dataset included in the script:

| TestCase | FailureRate | LinesChanged | ExecTime | RecentFails |
|--------
