# ML-Driven Test Case Prioritization
![Python](https://img.shields.io/badge/Python-3.10-blue)
![License](https://img.shields.io/badge/License-MIT-green)

This project demonstrates how to use **Machine Learning** to prioritize regression test cases based on historical execution data, helping reduce regression time and improve defect detection.
---

##  Overview
- Predicts which test cases are most likely to fail using a **Random Forest Classifier**.
- Prioritizes high-risk tests for execution.
- Includes **visualizations** showing feature relationships and test prioritization.

---

##  Features
- **FailureRate**: Historical failure frequency of the test case.  
- **LinesChanged**: Number of lines changed in related modules.  
- **ExecTime**: Execution time of the test case.  
- **RecentFails**: Number of recent failures in related modules.  

---

## Target
- **Label**: 1 = likely fail (high priority), 0 = likely pass (low priority).

---

##  Visualizations
**Example charts generated by the script:**

- **Bar chart**: Shows predicted failure probabilities of test cases.  

![Bar Chart Example](path/to/bar_chart.png)  <!-- Replace with actual screenshot -->

- **Pairplot**: Shows feature relationships and how they influence test case priority.  

![Pairplot Example](path/to/pairplot.png)  <!-- Replace with actual screenshot -->

> Tip: Replace the placeholder images with screenshots or GIFs generated when running the script.

---

## Dummy Data
Example dataset included in the script:

| TestCase | FailureRate | LinesChanged | ExecTime | RecentFails |
|--------
